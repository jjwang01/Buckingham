{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook goes through how I'm parsing the data one step at a time, for Patient GF101, Insulin1, Aug24-31. Hopefully I'll be able to get to the plotted graph by the end of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Passed header names mismatches usecols",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-391c357eabc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                     \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mu_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                     )\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:6175)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header (pandas/_libs/parsers.c:10631)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Passed header names mismatches usecols"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "u_cols = ['Date', 'Time', 'Timestamp', 'Bolus Type', 'Bolus Volume Selected (U)', 'Bolus Volume Delivered (U)', 'Sensor Glucose (mg/dL)']\n",
    "filename = '670GF108_Insulin1_Carelink_SEP20-27.csv'\n",
    "\n",
    "data = pd.read_csv(\n",
    "                    filename, \n",
    "                    skiprows=range(11),\n",
    "                    usecols=u_cols,\n",
    "                    )\n",
    "\n",
    "# drop all the rows that don't give us any valuable information regarding blood glucose and insulin boluses\n",
    "data = data.dropna(thresh=4)\n",
    "data = data.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've loaded the csv into the DataFrame \"data\" using only the columns I deemed necessary. I also got rid of the first few rows because they aren't formatted the same way that the rest of the file is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# off by one -- on Excel file indexing starts with 1, but indexing starts with 0 on pandas\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the cells that don't contain any values in Excel are shown as \"Not a Number\" in pandas. I used integer-location based indexing to make sure that the bolus volumes that I need are in the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot of waste data in the csv files, specifically the days when the patient is not on their meal challenge. Thankfully, there's an Excel file with dates during which the subjects are on their meal challenges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import ExcelFile\n",
    "\n",
    "# for this specific patient, 670GF101, the meal dates for Insulin 1 were from 8/29 to 8/31\n",
    "# the first and second row contain column names, so we skip those\n",
    "ex = pd.read_excel(\n",
    "                    '670G Fiasp Subject Dates.xlsx', \n",
    "                    sheet_name='Sheet1', \n",
    "                    skiprows=range(1)\n",
    "                    )\n",
    "\n",
    "ex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = \"\"\n",
    "end = \"\"\n",
    "\n",
    "# iterate through the first column to match patient name\n",
    "for row in ex.itertuples():\n",
    "    # the first element in each row/tuple will be the index\n",
    "    if row[1] == filename[:8]:\n",
    "        if filename[9:17] == 'Insulin1':\n",
    "            start = row[4][0:5]\n",
    "            end = row[4][6:]\n",
    "        elif filename[9:17] == 'Insulin2':\n",
    "            start = row[7][0:5]\n",
    "            end = row[7][6:]\n",
    "        \n",
    "# add years\n",
    "start += \"/18\"\n",
    "end += \"/18\"\n",
    "        \n",
    "print(start,end) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can just check for these dates within in the DataFrame \"data\", and then remove all the values that are not associated with those dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import datetime, time, timedelta\n",
    "\n",
    "# convert start and end into datetime objects\n",
    "start = datetime.strptime(start, \"%m/%d/%y\")\n",
    "end = datetime.strptime(end, \"%m/%d/%y\")\n",
    "\n",
    "print (start, end)\n",
    "\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data['Time'] = pd.to_datetime(data['Time']).dt.time\n",
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After converting all dates to a datetime object, we can iterate through and see which dates are within the range we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_date = start\n",
    "end_date = end + timedelta(days=1)\n",
    "print(end_date)\n",
    "\n",
    "start_row = 0\n",
    "end_row = 0\n",
    "\n",
    "# track index of the first occurrence of our start date and the last occurrence of our end date\n",
    "# e.g. the first occurrence of the end date + 1\n",
    "for index, row in data.iterrows():\n",
    "    if row[1] == start_date:\n",
    "        start_row = index\n",
    "        break\n",
    "for index, row in data.iterrows():\n",
    "    if row[1] == end_date:\n",
    "        end_row = index\n",
    "        break\n",
    "        \n",
    "# last date on csv was the last date of meal trial\n",
    "if end_row == 0:\n",
    "    end_row = data.tail(1).index.item()\n",
    "    \n",
    "print(start_row, end_row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of all the junk dates we don't need to look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_extracted = data[start_row:end_row]\n",
    "data_extracted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We should segment our meal period into three separate days, breakfast and dinner, then gather statistics about them individually. This notebook will focus on dinner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_day1 = data_extracted[data_extracted.Date == start]\n",
    "data_day2 = data_extracted[data_extracted.Date == start + timedelta(days=1)]\n",
    "data_day3 = data_extracted[data_extracted.Date == end]\n",
    "\n",
    "dates = [data_day1, data_day2, data_day3]\n",
    "\n",
    "# create an array of dates that have only glucose values\n",
    "data_day1_glucose_graph = data_day1.dropna(subset=['Sensor Glucose (mg/dL)'])\n",
    "data_day2_glucose_graph = data_day2.dropna(subset=['Sensor Glucose (mg/dL)'])\n",
    "data_day3_glucose_graph = data_day3.dropna(subset=['Sensor Glucose (mg/dL)'])\n",
    "\n",
    "dates_glucose_graph = [data_day1_glucose_graph, data_day2_glucose_graph, data_day3_glucose_graph]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just graph out data first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = dates_glucose_graph[0].plot(kind='line', x='Time', y='Sensor Glucose (mg/dL)', color='red')\n",
    "dates_glucose_graph[1].plot(ax=ax, kind='line', x='Time', y='Sensor Glucose (mg/dL)', color='green')\n",
    "dates_glucose_graph[2].plot(ax=ax, kind='line', x='Time', y='Sensor Glucose (mg/dL)', color='blue')\n",
    "plt.ylim(0,300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each day, we want to gather the breakfast bolus metric, the time the bolus is taken, etc. We also have to keep in mind that some breakfasts will have to be thrown out if there's another bolus within 3 hours of the breakfast bolus.\n",
    "\n",
    "Results were recorded in order of [bolus, bolus_time, baseline_glucose, glucose_max, delta_max, T_max, glucose_min, delta_min, T_min, T_halfmax].\n",
    "\n",
    "Once we have a DataFrame for each meal (breakfast_period), starting with the initial breakfast bolus and ending after an hour and a half, we can scale all glucose values according to the baseline glucose and all timestamps according to the time the insulin bolus was delivered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# just graph out an hour before and 3 hours after the initial bolus to see what the curves would look like\n",
    "to_graph = []\n",
    "\n",
    "for day in dates:\n",
    "    bolus_time = time(0,0,0) # will become datetime later\n",
    "    bolus_index = 0\n",
    "    \n",
    "    # find when the breakfast bolus is\n",
    "    for index, row in day.iterrows():\n",
    "    # if time of the row is in between 6:00:00 and 10:00:00, and the bolus amount is larger than 1\n",
    "        if row['Time'] <= time(10, 0, 0) and row['Time'] >= time(6, 0, 0) and row['Bolus Volume Selected (U)'] >= 1 and row['Bolus Volume Delivered (U)'] >= 1: \n",
    "            bolus_time = row['Timestamp']\n",
    "            bolus_index = index\n",
    "            graph = (day[(day['Timestamp'] <= (day.loc[bolus_index]['Timestamp'] + timedelta(hours=3))) &\n",
    "                          (day['Timestamp'] >= (day.loc[bolus_index]['Timestamp'] - timedelta(hours=1)))])\n",
    "            graph = graph.dropna(subset=['Sensor Glucose (mg/dL)'])\n",
    "            graph['Time_delta'] = graph['Timestamp'] - bolus_time\n",
    "            to_graph.append(graph)\n",
    "            \n",
    "    \n",
    "ax = to_graph[0].plot(kind='line', x='Time_delta', y='Sensor Glucose (mg/dL)', color='red')     \n",
    "to_graph[1].plot(ax=ax, kind='line', x='Time_delta', y='Sensor Glucose (mg/dL)', color='green')\n",
    "#to_graph[2].plot(ax=ax, kind='line', x='Time_delta', y='Sensor Glucose (mg/dL)', color='blue')\n",
    "plt.ylim(0,300)\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# day 1 has a sensor error b/c calibration wasn't conducted in time\n",
    "# watch out for day 3, that should be eliminated! one bolus @ 7:58:54 and another @ 8:53:05\n",
    "\n",
    "breakfasts = []\n",
    "results = []\n",
    "\n",
    "for day in dates:\n",
    "    bolus = 0\n",
    "    bolus_time = time(0,0,0)\n",
    "    baseline_glucose = 0\n",
    "    bolus_index = 0\n",
    "    possible_baseline_glucoses = []\n",
    "    second_bolus_found = False\n",
    "    \n",
    "    # get the breakfast bolus metric -- should be from 6 am to 10 am\n",
    "    for index, row in day.iterrows():\n",
    "        if second_bolus_found:\n",
    "            bolus = 0\n",
    "            bolus_time = time(0, 0, 0)\n",
    "            baseline_glucose = 0\n",
    "            possible_baseline_glucoses = []\n",
    "            break\n",
    "        \n",
    "        # if time of the row is in between 6:00:00 and 10:00:00, and the bolus amount is larger than 1\n",
    "        if row['Time'] <= time(10, 0, 0) and row['Time'] >= time(6, 0, 0) and row['Bolus Volume Selected (U)'] >= 1 and row['Bolus Volume Delivered (U)'] >= 1: \n",
    "            # check if there's already been a bolus registered -- in that case, skip this day\n",
    "            if bolus > 0:\n",
    "                second_bolus_found = True\n",
    "            # if not, record the metric, timestamp, and glucose level at that time\n",
    "            else:\n",
    "                bolus = row['Bolus Volume Delivered (U)']\n",
    "                bolus_time = row['Timestamp']\n",
    "                bolus_index = index\n",
    "                # glucose_baseline must be within 20 minutes beforehand or 5 minutes after the bolus\n",
    "                possible_baseline_glucoses = day[(day['Timestamp'] >= (row['Timestamp'] - timedelta(minutes=20))) & \n",
    "                                      (day['Timestamp'] <= (row['Timestamp'] + timedelta(minutes=5))) & \n",
    "                                      ((day['Sensor Glucose (mg/dL)']).isnull() == False)]\n",
    "            \n",
    "        if row['Time'] > time(10, 0, 0):\n",
    "            break\n",
    "\n",
    "    min_time_diff = timedelta.max\n",
    "    # for each possible baseline value, check which timestamp is closest to insulin bolus time\n",
    "    if not second_bolus_found:\n",
    "        for index, possible_baseline in possible_baseline_glucoses.iterrows():\n",
    "            # using time objects instead of datetime objects b/c looping through different days\n",
    "            time_diff = abs(datetime.combine(datetime.min, possible_baseline['Time']) - datetime.combine(datetime.min, bolus_time.time()))\n",
    "            if time_diff < min_time_diff:\n",
    "                min_time_diff = time_diff\n",
    "                baseline_glucose = possible_baseline['Sensor Glucose (mg/dL)']\n",
    "    else:\n",
    "        # TODO: what to do for results of N/A dates?\n",
    "        break\n",
    "  \n",
    "    # within the next 1:30, we need to look for the maximum glucose level, minimum glucose level,\n",
    "    # don't forget to record the T_max and T_1/2max\n",
    "    glucose_max = 0\n",
    "    delta_max = 0\n",
    "    T_max = 0\n",
    "    glucose_min = sys.maxsize\n",
    "    delta_min = 0\n",
    "    T_min = 0\n",
    "    T_halfmax = 0\n",
    "    \n",
    "    breakfast_period = day[(day['Timestamp'] <= (day.loc[bolus_index]['Timestamp'] + timedelta(hours=1, minutes=30))) &\n",
    "                          (day['Timestamp'] >= day.loc[bolus_index]['Timestamp'])]\n",
    "    \n",
    "    for index, entry in breakfast_period.iterrows():\n",
    "        if entry['Sensor Glucose (mg/dL)'] > glucose_max:\n",
    "            glucose_max = entry['Sensor Glucose (mg/dL)']\n",
    "            T_max = entry['Timestamp']\n",
    "        if entry['Sensor Glucose (mg/dL)'] < glucose_min:\n",
    "            glucose_min = entry['Sensor Glucose (mg/dL)']\n",
    "            T_min = entry['Timestamp']\n",
    "            \n",
    "    delta_max = glucose_max - baseline_glucose\n",
    "    delta_min = glucose_min - baseline_glucose\n",
    "    \n",
    "    glucose_halfmax = baseline_glucose + delta_max / 2\n",
    "    for index, entry in breakfast_period.iterrows():\n",
    "        # captures the first instance of a glucose reading at 1/2 max\n",
    "        if (entry['Sensor Glucose (mg/dL)'] <= glucose_halfmax + 1) or (entry['Sensor Glucose (mg/dL)'] >= glucose_halfmax - 1):\n",
    "            T_halfmax = entry['Timestamp']\n",
    "            break\n",
    "    \n",
    "    result = [bolus, bolus_time, baseline_glucose, glucose_max, delta_max, T_max, glucose_min, delta_min, T_min, T_halfmax]\n",
    "    results.append(result)\n",
    "    \n",
    "    # add new columns 'Glucose_delta' and 'Time-delta' to plot later on\n",
    "    # TODO: deal with warning\n",
    "    breakfast_period['Time_delta'] = breakfast_period['Timestamp'] - bolus_time\n",
    "    breakfast_period['Glucose_delta'] = breakfast_period['Sensor Glucose (mg/dL)'] - baseline_glucose\n",
    "    \n",
    "    breakfasts.append(breakfast_period)\n",
    "\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can plot them on the same graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "breakfast_period_graph_0 = breakfasts[0].dropna(subset=['Glucose_delta'])\n",
    "ax = breakfast_period_graph_0.plot(kind='line', x='Time_delta', y='Glucose_delta')\n",
    "for i in range(1, len(breakfasts)):\n",
    "    breakfast_period_graph = breakfasts[i].dropna(subset=['Glucose_delta'])\n",
    "    breakfast_period_graph.plot(ax=ax, kind='line', x='Time_delta', y='Glucose_delta')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
